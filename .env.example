# Sena Environment Variables Configuration
# Copy this file to .env and edit to customize Sena settings via environment variables.
# Environment variables override values in config/local.toml, which override config/default.toml.

# LLM Configuration
# Name of the LLM model to use (must be available in Ollama)
# Default: ministral-3:14b
# SENA_MODEL=ministral-3:14b

# Whether to stream token responses (true) or wait for full response (false)
# Default: true
# SENA_STREAM=true

# Enable extended thinking mode for models that support it
# Default: false
# SENA_THINK=false

# Agent Configuration
# Maximum number of internal state transitions per drain() call
# Prevents infinite loops if a state machine gets stuck
# Default: 8
# SENA_MAX_INTERNAL_STEPS=8

# Maximum number of non-system messages to keep in conversation history
# Older messages are trimmed when this limit is exceeded
# Default: 20
# SENA_MAX_HISTORY_MESSAGES=20

# Enable DEBUG-level logging for state transitions and configuration
# When false, only INFO level and above are logged
# Default: false
# SENA_DEBUG=false

# Ollama Configuration
# Base URL for the Ollama API (used by Sena and Docker Compose)
# Windows/macOS default:
# OLLAMA_BASE_URL=http://host.docker.internal:11434
# Linux with host-gateway:
# OLLAMA_BASE_URL=http://host.docker.internal:11434

# Container timezone used by Docker Compose (affects reminder local times)
# Default in compose is Europe/Helsinki.
# TZ=Europe/Helsinki
